{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36041,
     "status": "ok",
     "timestamp": 1738282773302,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "yMHvfb2gur4_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from configparser import ConfigParser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "# import faiss\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report,precision_recall_fscore_support\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMj9okOi2vh2"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1738282873241,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "t-u7tbS7uzNf"
   },
   "outputs": [],
   "source": [
    "train_dir = \"path_to_train_directory\"\n",
    "test_dir =  \"path_to_test_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738282874793,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "bn1IDkL4Knbv"
   },
   "outputs": [],
   "source": [
    "def get_data(root_directory):\n",
    "    image_text_pairs = []\n",
    "    # for label in os.listdir(root_directory):\n",
    "    for label in [\"normal\", \"lesion\"]:\n",
    "      label_dir = os.path.join(root_directory, label)\n",
    "      if os.path.isdir(label_dir):\n",
    "        # Iterate through each image in the label directory\n",
    "        for image_file in os.listdir(label_dir):\n",
    "            image_path = os.path.join(label_dir, image_file)\n",
    "            # Check if the path is a file (to avoid subdirectories)\n",
    "            if os.path.isfile(image_path):\n",
    "                # Add the image path and label to the list\n",
    "                image_text_pairs.append((image_path, label))\n",
    "    return image_text_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1738282877976,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "1FgXjUbrKIw7",
    "outputId": "95a50288-9706-40f5-eb95-63cbe67d52a5"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(get_data(test_dir), columns=['image path','label'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2333,
     "status": "ok",
     "timestamp": 1738282882387,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "n1_x_vXL4ptc",
    "outputId": "745c5334-830b-413d-abf5-7cbd70eaeaf1"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(get_data(train_dir), columns=['image path','label'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpByc5aTwi96"
   },
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1738283079143,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "I7k8FU6NwNOQ"
   },
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "def get_image_encoder():\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])  # Remove classification layer\n",
    "    resnet50.eval()\n",
    "    return resnet50\n",
    "\n",
    "\n",
    "def extract_number_from_filename(file_path):\n",
    "    # Get the file name from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Use regular expressions to find all numbers in the file name\n",
    "    match = re.search(r'\\d+', file_name)\n",
    "    return int(match.group())\n",
    "\n",
    "\n",
    "def get_preprocessor():\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return preprocess\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    # print(a.shape)\n",
    "    # print(b.shape)\n",
    "    a_norm = np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a, b.T) / (a_norm * b_norm)\n",
    "# def cosine_similarity(a, b):\n",
    "#     a = np.atleast_2d(a)\n",
    "#     b = np.atleast_2d(b)\n",
    "\n",
    "#     a_norm = np.linalg.norm(a, axis=1, keepdims=True)\n",
    "#     b_norm = np.linalg.norm(b, axis=1, keepdims=True)\n",
    "\n",
    "#     # Avoid division by zero\n",
    "#     a_norm[a_norm == 0] = 1e-10\n",
    "#     b_norm[b_norm == 0] = 1e-10\n",
    "\n",
    "#     similarity = np.dot(a, b.T) / (a_norm * b_norm)\n",
    "\n",
    "#     # Clip to ensure the range is [-1, 1]\n",
    "#     return similarity\n",
    "\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self,dataset,skip_list=None):\n",
    "        # Load the pre-trained ResNet50 model without the top layer (for feature extraction)\n",
    "        self.dataset = dataset\n",
    "        self.skip_list = skip_list\n",
    "        self.model = get_image_encoder()\n",
    "        self.preprocessor = get_preprocessor()\n",
    "        self.lesion_embeddings_df = None\n",
    "        self.lesion_paths = []\n",
    "        self.normal_embeddings_df = None\n",
    "        self.normal_paths = []\n",
    "        self.index_lesion = None\n",
    "        self.index_normal = None\n",
    "        self.top_5_lesion_df = []\n",
    "        self.top_5_normal_df = []\n",
    "        self.normal_embeddings_path = \"normla_embeddings.pkl\"\n",
    "        self.lesion_embeddings_path = \"lesion_embeddings.pkl\"\n",
    "        self.dimension = None\n",
    "\n",
    "    def extract_embedding(self,image_path):\n",
    "      img = Image.open(image_path)\n",
    "      img = self.preprocessor(img).unsqueeze(0)  # Add batch dimension\n",
    "      with torch.no_grad():\n",
    "          embedding = self.model(img)\n",
    "      return embedding.squeeze().numpy()\n",
    "\n",
    "    def generate_embeddings(self,label):\n",
    "        embeddings = []\n",
    "        label_df = self.dataset[self.dataset[\"label\"]==label]\n",
    "        label_df.reset_index(inplace=True)\n",
    "        print(\"Generating embdeddibgs of \"+label+\" images....\")\n",
    "        # print(label_df.index)\n",
    "        # print(label_df.shape)\n",
    "        for idx in tqdm(label_df.index):\n",
    "            # print(idx)\n",
    "            img_path = label_df.iloc[idx][\"image path\"]\n",
    "            embedding = self.extract_embedding(img_path)\n",
    "            embeddings.append(np.array(embedding))\n",
    "        label_df[\"embeddings\"] = embeddings\n",
    "        return label_df\n",
    "\n",
    "\n",
    "    def load_ebmbeddings(self):\n",
    "        # Check and load or generate lesion embeddings\n",
    "        if os.path.exists(self.lesion_embeddings_path):\n",
    "            print(\"Lesion embeddings file found. Loading embeddings...\")\n",
    "            self.lesion_embeddings_df = pd.read_pickle(self.lesion_embeddings_path)\n",
    "        else:\n",
    "            print(\"Lesion embeddings file not found. Generating embeddings...\")\n",
    "            self.lesion_embeddings_df = self.generate_embeddings(\"lesion\")\n",
    "            self.lesion_embeddings_df.to_pickle(self.lesion_embeddings_path)\n",
    "\n",
    "        # Check and load or generate normal embeddings\n",
    "        if os.path.exists(self.normal_embeddings_path):\n",
    "            print(\"Normal embeddings file found. Loading embeddings...\")\n",
    "            self.normal_embeddings_df = pd.read_pickle(self.normal_embeddings_path)\n",
    "        else:\n",
    "            print(\"Normal embeddings file not found. Generating embeddings...\")\n",
    "            self.normal_embeddings_df = self.generate_embeddings(\"normal\")\n",
    "            self.normal_embeddings_df.to_pickle(self.normal_embeddings_path)\n",
    "\n",
    "    # Function to perform a similarity search and retrieve top 10 images\n",
    "    def retrieve_top_k_images(self, query_image_path, embeddings_df,k=5):\n",
    "        image_paths = embeddings_df[\"image path\"]\n",
    "\n",
    "        embeddings = np.vstack(embeddings_df[\"embeddings\"].values)\n",
    "\n",
    "\n",
    "        # embeddings = np.expand_dims(embeddings, axis=0)\n",
    "\n",
    "        query_embedding = self.extract_embedding(query_image_path)\n",
    "        query_embedding = np.expand_dims(query_embedding, axis=0)\n",
    "\n",
    "        similarities = cosine_similarity(query_embedding, embeddings)\n",
    "\n",
    "        # Get the top-k indices based on similarity scores\n",
    "        top_k_indices = np.argsort(similarities[0])[::-1][:k]  # Sort in descending order\n",
    "\n",
    "        # Retrieve the corresponding image paths and similarities\n",
    "        top_k_images = [image_paths[i] for i in top_k_indices]\n",
    "        top_k_similarities = [similarities[0][i] for i in top_k_indices]\n",
    "\n",
    "        top_k_dict = {\n",
    "            \"top k images\":top_k_images,\n",
    "            \"top_k_similarities\": top_k_similarities\n",
    "        }\n",
    "        top_k_df=  pd.DataFrame(top_k_dict)\n",
    "        return top_k_df\n",
    "\n",
    "\n",
    "    # Retrieve top 5 images from Class A and Class B for a given query image\n",
    "    def retrieve_images(self, query_image_path):\n",
    "        self.top_5_lesion_df = self.retrieve_top_k_images(query_image_path, self.lesion_embeddings_df, k=15)\n",
    "        self.top_5_normal_df = self.retrieve_top_k_images(query_image_path, self.normal_embeddings_df, k=15)\n",
    "        return query_image_path, self.top_5_lesion_df, self.top_5_normal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1738283082698,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "HydndgKCsZ8B",
    "outputId": "7c0cf622-edef-46eb-ab4c-c8c5832e90e9"
   },
   "outputs": [],
   "source": [
    "retriever = Retriever(dataset = train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1738283082698,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "XpPQH55OSexz",
    "outputId": "12a83a71-a796-4bad-e563-6a228466e650"
   },
   "outputs": [],
   "source": [
    "retriever.load_ebmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1738283084723,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "X3VSNps1Mmy5",
    "outputId": "2a75b3e9-506f-4cff-fc21-8919e9e19363"
   },
   "outputs": [],
   "source": [
    "len(retriever.lesion_embeddings_df.iloc[0][\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738283085374,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "-_41xCD3Bi44"
   },
   "outputs": [],
   "source": [
    "random_test_img = test_df[\"image path\"][random.randint(0,200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1738283087681,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "lg_u-LzDtitI"
   },
   "outputs": [],
   "source": [
    "query_image_path, top_5_lesion_df, top_5_normal_df = retriever.retrieve_images(random_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1738283110481,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "VzKZqLwmH47_"
   },
   "outputs": [],
   "source": [
    "def show_top_k_images(query_image_path, top_lesion_images, top_normal_images,k=5):\n",
    "    # Load the query image\n",
    "    query_image = Image.open(query_image_path)\n",
    "\n",
    "    # Define figure layout based on the number of top images to display\n",
    "    fig, axes = plt.subplots(3, k, figsize=(5 * k, 20))\n",
    "\n",
    "    # Show the query image in the top row\n",
    "    axes[0, 0].imshow(query_image)\n",
    "    axes[0, 0].set_title(\"Query Image\")\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    # Fill the rest of the top row with empty plots if k > 1\n",
    "    skip_axes = [0,1,3,4]\n",
    "    for ax in axes[0, 1:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Display top lesion images in the second row\n",
    "    for i, lesion_img_path in enumerate(top_lesion_images[:k]):\n",
    "        lesion_img = Image.open(lesion_img_path)\n",
    "        axes[1, i].imshow(lesion_img)\n",
    "        axes[1, i].set_title(f\"Lesion Image {i + 1}\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    # Display top normal images in the third row\n",
    "    for i, normal_img_path in enumerate(top_normal_images[:k]):\n",
    "        normal_img = Image.open(normal_img_path)\n",
    "        axes[2, i].imshow(normal_img)\n",
    "        axes[2, i].set_title(f\"Normal Image {i + 1}\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "\n",
    "    # Adjust layout to avoid overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GI6ydHcUJDUB"
   },
   "outputs": [],
   "source": [
    "# show_top_k_images(query_image_path, top_5_lesion_df[\"top k images\"].values, top_5_normal_df[\"top k images\"].values, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfCeJH2w11b7"
   },
   "source": [
    "# Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1738283143667,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "OStYL-0U2LEl"
   },
   "outputs": [],
   "source": [
    "def to_base64(path):\n",
    "    with open(path, 'rb') as image_file:\n",
    "        image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return image_base64\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, lesion_image_list, test_image_path, max_size, normal_image_list=None):\n",
    "        if normal_image_list is None:\n",
    "            normal_image_list = []\n",
    "        self.lesion_image_list = lesion_image_list\n",
    "        self.normal_image_list = normal_image_list\n",
    "        self.max_size = max_size\n",
    "        self.test_image = test_image_path\n",
    "        # self.lesion_descriptions = get_lesion_description()\n",
    "        self.messages = None\n",
    "\n",
    "    def get_image_data(self, img_path):\n",
    "        return self.resize_and_convert_to_base64(img_path)\n",
    "\n",
    "    def resize_and_convert_to_base64(self, image_path):\n",
    "        size = self.max_size\n",
    "        # Open the image file\n",
    "        with Image.open(image_path) as img:\n",
    "            # Check the size of the image\n",
    "            width, height = img.size\n",
    "\n",
    "            # Resize if either dimension is greater than 800 pixels\n",
    "            if width > size or height > size:\n",
    "                # Determine the new size while maintaining the aspect ratio\n",
    "                if width > height:\n",
    "                    new_width = size\n",
    "                    new_height = int((size / width) * height)\n",
    "                else:\n",
    "                    new_height = size\n",
    "                    new_width = int((size / height) * width)\n",
    "\n",
    "                # Resize the image\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Convert the image to base64\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            return img_base64\n",
    "\n",
    "    def get_content(self):\n",
    "        content_list = [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"Here are some images and their respective classes. Please act as an image classifier and classify the last image as either \"lesion\" or \"normal\" in the given format.\n",
    "                       Respond only with either \"lesion\" or \"normal\".\n",
    "                       Do not write any explanations, comments, or plain text.\"\"\"\n",
    "        }]\n",
    "        for img_path in self.lesion_image_list:\n",
    "            content_list.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(img_path)}\"\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            content_list.append(\n",
    "                {\"type\": \"text\", \"text\": \"lesion\"}\n",
    "            )\n",
    "        for img_num in self.normal_image_list:\n",
    "            content_list.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(img_path)}\"\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            content_list.append(\n",
    "                {\"type\": \"text\", \"text\": \"normal\"}\n",
    "            )\n",
    "\n",
    "\n",
    "        return content_list\n",
    "\n",
    "    def get_message(self):\n",
    "        self.messages = [\n",
    "            {\"role\": \"user\", \"content\": self.get_content()},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(self.test_image)}\"\n",
    "                    }\n",
    "                }]\n",
    "             }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyCQoSDlb0M5"
   },
   "source": [
    "# Augmentation and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1738283149587,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "f8nLxMl-MuPI"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = \"your api key\")\n",
    "\n",
    "\n",
    "def predict(lesion_image_list, max_size, normal_image_list, test_image_path):\n",
    "    image_processor = Processor(lesion_image_list=lesion_image_list,\n",
    "                                max_size=max_size,\n",
    "                                normal_image_list=normal_image_list,\n",
    "                                test_image_path = test_image_path)\n",
    "\n",
    "    image_processor.get_message()\n",
    "    messages = image_processor.messages\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-2024-08-06',\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2813490,
     "status": "ok",
     "timestamp": 1738286279243,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "ymoU8sYj8gTz",
    "outputId": "0e932a4a-7c93-4879-a4c3-fd2fcb054db6"
   },
   "outputs": [],
   "source": [
    "test_image_list = test_df[\"image path\"]\n",
    "\n",
    "max_size = 200\n",
    "num_examples = 5\n",
    "\n",
    "results = {}\n",
    "\n",
    "num_runs = 1\n",
    "\n",
    "for run in range(num_runs):\n",
    "  print(f\"Run {run+1} of {num_runs}\")\n",
    "  results[f\"Run{run+1}\"] = {}\n",
    "  for idx in tqdm(test_df.index):\n",
    "  # for idx in tqdm(range(10)):\n",
    "      expectation = test_df[\"label\"][idx]\n",
    "      test_image_path = test_df[\"image path\"][idx]\n",
    "      query_image_path, top_5_lesion_images, top_5_normal_images= retriever.retrieve_images(test_image_path)\n",
    "      lesion_img_list = top_5_lesion_images[\"top k images\"].values\n",
    "      normal_img_list = top_5_normal_images[\"top k images\"].values\n",
    "\n",
    "\n",
    "      test_image_name = query_image_path[94:]\n",
    "      prediction = predict(lesion_image_list=lesion_img_list,\n",
    "                            max_size=max_size,\n",
    "                            normal_image_list=normal_img_list,\n",
    "                          test_image_path = query_image_path\n",
    "                          )\n",
    "\n",
    "      results[f\"Run{run+1}\"][test_image_name] = {\n",
    "          \"query_image_path\": query_image_path,\n",
    "          \"expectation\": expectation,\n",
    "          \"prediction\": prediction,\n",
    "      }\n",
    "  # Save a checkpoint after each run with a descriptive filename\n",
    "  checkpoint_path = \"Result.json\"\n",
    "  with open(checkpoint_path, \"w\") as outfile:\n",
    "      json.dump(results, outfile)\n",
    "  print(f\"Checkpoint saved. Data available up to Run {run + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGRDYzrgQK0N"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1738286279244,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "deAk9AgB312l"
   },
   "outputs": [],
   "source": [
    "with open(f\"Results.json\", 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1738286279244,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "qSB8KVAzQNBE",
    "outputId": "6bdbd22f-e6b2-4b7a-e51d-303322ed1f93"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define class mappings\n",
    "class_mapping = {\"normal\": 0,\"lesion\": 1}\n",
    "\n",
    "# Prepare a figure for subplots\n",
    "num_runs = len(results)\n",
    "fig, axes = plt.subplots(1, num_runs, figsize=(20 * num_runs, 6), sharey=True)\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "# Process results for each run\n",
    "for idx, (run_name, run_data) in enumerate(results.items()):\n",
    "    # Initialize lists for actual and prediction values\n",
    "    actual = []\n",
    "    prediction = []\n",
    "    unknown_classes = []\n",
    "    metrics[run_name] = {}\n",
    "\n",
    "    # Process each image in the run\n",
    "    for img, data in tqdm(run_data.items(), desc=f\"Processing images for {run_name}\"):\n",
    "        actual_class = data[\"expectation\"]\n",
    "        pred_class = data[\"prediction\"]\n",
    "\n",
    "        if pred_class not in class_mapping:\n",
    "            unknown_classes.append((img, actual_class, pred_class))\n",
    "            print(f\"Unknown class in prediction: {pred_class}\")\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            pred_label = class_mapping[pred_class]\n",
    "            prediction.append(pred_label)\n",
    "            actual_label = class_mapping[actual_class]\n",
    "            actual.append(actual_label)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(actual, prediction)\n",
    "    precision = precision_score(actual, prediction, average='binary', pos_label=class_mapping[\"lesion\"])\n",
    "    recall = recall_score(actual, prediction, average='binary', pos_label=class_mapping[\"lesion\"])\n",
    "    f1 = f1_score(actual, prediction, average='binary', pos_label=class_mapping[\"lesion\"])\n",
    "\n",
    "    metrics[run_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"unknown_classes\": unknown_classes\n",
    "    }\n",
    "    # Compute confusion matrix\n",
    "    matrix = confusion_matrix(actual, prediction)\n",
    "\n",
    "    # Plot confusion matrix in a subplot\n",
    "    ax = axes[idx] if num_runs > 1 else axes\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=list(class_mapping.keys()))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    ax.set_title(\n",
    "        f\"{run_name}\\n\"\n",
    "        f\"Acc: {accuracy:.2f}, Prec: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}\"\n",
    "    )\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNCUmbH836k+XGGS945oTvb",
   "mount_file_id": "1eX7j3zT8fw3zwK_cgvahgf_cUYoSjqRX",
   "provenance": [
    {
     "file_id": "1pLz35qvgWpST1l-0aGN4bbOcOizhdBVq",
     "timestamp": 1736950516239
    },
    {
     "file_id": "1Zx0jp0Ou_5sude3mKLOXS-3kRlorEPQ8",
     "timestamp": 1732952694297
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
