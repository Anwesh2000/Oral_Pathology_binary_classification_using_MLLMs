{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 35996,
     "status": "ok",
     "timestamp": 1739412755533,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "yMHvfb2gur4_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from configparser import ConfigParser\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report,precision_recall_fscore_support\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL9jNQAGKlPP"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739412755534,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "5LwM58h34P4Y"
   },
   "outputs": [],
   "source": [
    "train_dir = \"path_to_train_directory\"\n",
    "test_dir =  \"path_to_test_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739412755534,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "QCOIVBWl4P4Z"
   },
   "outputs": [],
   "source": [
    "def get_data(root_directory):\n",
    "    image_text_pairs = []\n",
    "    # for label in os.listdir(root_directory):\n",
    "    for label in [\"lesion\",\"normal\",\"variation in normal\",\"red lesion\"]:\n",
    "      label_dir = os.path.join(root_directory, label)\n",
    "      if os.path.isdir(label_dir):\n",
    "        # Iterate through each image in the label directory\n",
    "        for image_file in os.listdir(label_dir):\n",
    "            image_path = os.path.join(label_dir, image_file)\n",
    "            # Check if the path is a file (to avoid subdirectories)\n",
    "            if os.path.isfile(image_path):\n",
    "                # Add the image path and label to the list\n",
    "                if label != 'normal':\n",
    "                    image_text_pairs.append((image_path, 'lesion'))\n",
    "                    continue\n",
    "                image_text_pairs.append((image_path, label))\n",
    "    return image_text_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1739412756932,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "1FgXjUbrKIw7",
    "outputId": "f7930faf-9a6d-44d2-ef4e-62e67787f1c5"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(get_data(test_dir), columns=['image path','label'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 2093,
     "status": "ok",
     "timestamp": 1739412761062,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "n1_x_vXL4ptc",
    "outputId": "d0d1d815-acdb-4418-fe7e-a5f5b0b3d805"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(get_data(train_dir), columns=['image path','label'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfCeJH2w11b7"
   },
   "source": [
    "# Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739412761062,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "OStYL-0U2LEl"
   },
   "outputs": [],
   "source": [
    "def to_base64(path):\n",
    "    with open(path, 'rb') as image_file:\n",
    "        image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return image_base64\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, lesion_image_list,max_size, normal_image_list,test_image_path):\n",
    "        self.lesion_image_list = lesion_image_list\n",
    "        self.normal_image_list = normal_image_list\n",
    "        self.max_size = max_size\n",
    "        self.test_image = test_image_path\n",
    "        self.messages = None\n",
    "\n",
    "    def get_image_data(self, img_path):\n",
    "        return self.resize_and_convert_to_base64(img_path)\n",
    "\n",
    "    def resize_and_convert_to_base64(self, image_path):\n",
    "        size = self.max_size\n",
    "        # Open the image file\n",
    "        with Image.open(image_path) as img:\n",
    "            # Check the size of the image\n",
    "            width, height = img.size\n",
    "\n",
    "            # Resize if either dimension is greater than 800 pixels\n",
    "            if width > size or height > size:\n",
    "                # Determine the new size while maintaining the aspect ratio\n",
    "                if width > height:\n",
    "                    new_width = size\n",
    "                    new_height = int((size / width) * height)\n",
    "                else:\n",
    "                    new_height = size\n",
    "                    new_width = int((size / height) * width)\n",
    "\n",
    "                # Resize the image\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Convert the image to base64\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            return img_base64\n",
    "\n",
    "    def get_content(self):\n",
    "        content_list = [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"Here are some images and their respective classes. Please act as an image classifier and classify the last image as either \"abnormal\" or \"normal\" in the given format.\n",
    "                       Respond only with either \"abnormal\" or \"normal\".\n",
    "                       Do not write any explanations, comments, or plain text.\"\"\"\n",
    "        }]\n",
    "        for img_path in self.lesion_image_list:\n",
    "            content_list.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(img_path)}\"\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            content_list.append(\n",
    "                {\"type\": \"text\", \"text\": \"abnormal\"}\n",
    "            )\n",
    "        for img_num in self.normal_image_list:\n",
    "            content_list.append(\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(img_path)}\"\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            content_list.append(\n",
    "                {\"type\": \"text\", \"text\": \"normal\"}\n",
    "            )\n",
    "\n",
    "\n",
    "        return content_list\n",
    "\n",
    "    def get_message(self):\n",
    "        self.messages = [\n",
    "            {\"role\": \"user\", \"content\": self.get_content()},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpg;base64,{self.get_image_data(self.test_image)}\"\n",
    "                    }\n",
    "                }]\n",
    "             }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K9NudDfTPl6"
   },
   "source": [
    "## Setting up API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1739412765535,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "f8nLxMl-MuPI"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = \"your api key\")\n",
    "\n",
    "def predict(lesion_image_list, max_size, normal_image_list, test_image_path):\n",
    "    image_processor = Processor(lesion_image_list=lesion_image_list,\n",
    "                                max_size=max_size,\n",
    "                                normal_image_list=normal_image_list,\n",
    "                                test_image_path = test_image_path)\n",
    "\n",
    "    image_processor.get_message()\n",
    "    messages = image_processor.messages\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-2024-11-20',\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFVgFJBz-Pko"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6620520,
     "status": "ok",
     "timestamp": 1739419402623,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "hEDDs2Dw-Pxn",
    "outputId": "8bcff56c-484a-4c3c-c94a-dbf11c126dfa"
   },
   "outputs": [],
   "source": [
    "max_size = 200\n",
    "num_examples = 5\n",
    "\n",
    "results = {}\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "for run in range(1,num_runs):\n",
    "  print(f\"Run {run+1} of {num_runs}\")\n",
    "  results[f\"Run{run+1}\"] = {}\n",
    "  for idx in tqdm(test_df.index):\n",
    "  # for idx in tqdm(range(2)):\n",
    "\n",
    "      lesion_img_list = train_df[train_df[\"label\"] == \"lesion\"].sample(n=num_examples)['image path']\n",
    "      normal_img_list = train_df[train_df[\"label\"] == \"normal\"].sample(n=num_examples)['image path']\n",
    "\n",
    "      query_image_path = test_df[\"image path\"][idx]\n",
    "\n",
    "      expectation = test_df[\"label\"][idx]\n",
    "      if expectation == \"lesion\":\n",
    "          expectation = \"abnormal\"\n",
    "      test_image_name = query_image_path[94:]\n",
    "      prediction = predict(lesion_image_list=lesion_img_list,\n",
    "                            max_size=max_size,\n",
    "                            normal_image_list=normal_img_list,\n",
    "                          test_image_path = query_image_path\n",
    "                          )\n",
    "\n",
    "      results[f\"Run{run+1}\"][test_image_name] = {\n",
    "          \"query\": query_image_path,\n",
    "          \"expectation\": expectation,\n",
    "          \"prediction\": prediction\n",
    "      }\n",
    "  # Save a checkpoint after each run with a descriptive filename\n",
    "  checkpoint_path = \"Results.json\"\n",
    "  with open(checkpoint_path, \"w\") as outfile:\n",
    "      json.dump(results, outfile)\n",
    "  print(f\"Checkpoint saved. Data available up to Run {run + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zflDyG9nwzpb"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1739419552329,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "wyTqgYZTPhJg"
   },
   "outputs": [],
   "source": [
    "with open(\"Results.json\", 'r') as file:\n",
    "    results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1739419581260,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "LGSq7XugfDd7"
   },
   "outputs": [],
   "source": [
    "results.update(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1739419590758,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "CJxCCdahppla",
    "outputId": "ffba682b-ff8b-4933-a541-abf41ec9d508"
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2137,
     "status": "ok",
     "timestamp": 1739419601367,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "qSB8KVAzQNBE",
    "outputId": "22b77e76-3b3c-48d7-f810-6522fbb98612"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define class mappings\n",
    "class_mapping = {\"normal\": 0, \"abnormal\": 1}\n",
    "\n",
    "# Prepare a figure for subplots (2 rows, 3 columns)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))  # 2x3 grid\n",
    "axes = axes.ravel()  # Flatten the axes array for easy indexing\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "# Process results for each run\n",
    "for idx, (run_name, run_data) in enumerate(results.items()):\n",
    "    # Initialize lists for actual and prediction values\n",
    "    actual = []\n",
    "    prediction = []\n",
    "    unknown_classes = []\n",
    "    metrics[run_name] = {}\n",
    "\n",
    "    # Process each image in the run\n",
    "    for img, data in tqdm(run_data.items(), desc=f\"Processing images for {run_name}\"):\n",
    "        actual_class = data[\"expectation\"]\n",
    "        pred_class = data[\"prediction\"]\n",
    "\n",
    "        if pred_class not in class_mapping:\n",
    "            unknown_classes.append((img, actual_class, pred_class))\n",
    "            print(f\"Unknown class in prediction: {pred_class}\")\n",
    "            continue\n",
    "        else:\n",
    "            pred_label = class_mapping[pred_class]\n",
    "            prediction.append(pred_label)\n",
    "            actual_label = class_mapping[actual_class]\n",
    "            actual.append(actual_label)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(actual, prediction)\n",
    "    precision = precision_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"])\n",
    "    recall = recall_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"])\n",
    "    f1 = f1_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"])\n",
    "\n",
    "    metrics[run_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"unknown_classes\": unknown_classes\n",
    "    }\n",
    "\n",
    "    # Compute confusion matrix with specified labels\n",
    "    matrix = confusion_matrix(actual, prediction, labels=list(class_mapping.values()))\n",
    "\n",
    "    # Plot confusion matrix in a subplot\n",
    "    ax = axes[idx]  # Use the flattened axes array\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=list(class_mapping.keys()))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    ax.set_title(\n",
    "        f\"{run_name}\\n\"\n",
    "        f\"Acc: {accuracy:.2f}, Prec: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}\"\n",
    "    )\n",
    "\n",
    "# Hide the last subplot (6th subplot) if there are only 5 runs\n",
    "if len(results) < 6:\n",
    "    axes[-1].axis('off')  # Hide the last subplot\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1739419767772,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "14yAeNb5fe8_",
    "outputId": "0b5e4956-7ed2-4b72-a291-9683c4f2076d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define class mappings\n",
    "class_mapping = {\"normal\": 0, \"abnormal\": 1}\n",
    "\n",
    "# Example results dictionary (replace with your actual data)\n",
    "expert_list = ['resnet50_pretrained_cosine', 'resnet50_pretrained_one', 'resnet50_pretrained_euclidean', \"resnet50_pretrained_inf\",\"resnet50_pretrained_-inf\", \"Mixture of Experts(5_experts)\",'resnet50_pretrained_random']\n",
    "\n",
    "all_expert_5_runs_results = {\n",
    "    \"few shot\": [results[\"Run1\"], results[\"Run2\"], results[\"Run3\"], results[\"Run4\"], results[\"Run5\"]],\n",
    "}\n",
    "\n",
    "# Function to extract the \"output\" value from the prediction string\n",
    "def extract_output(prediction):\n",
    "    if isinstance(prediction, str):\n",
    "        return prediction.strip().lower()\n",
    "    elif isinstance(prediction, dict):\n",
    "        return prediction.get(\"output\", \"\").strip().lower()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Function to create a DataFrame with metrics for each expert and run\n",
    "def create_metrics_dataframe(all_expert_5_runs_results, class_mapping):\n",
    "    # Initialize a dictionary to store metrics for each expert\n",
    "    expert_metrics = {}\n",
    "\n",
    "    for expert_name, expert_runs in all_expert_5_runs_results.items():\n",
    "        # Initialize a dictionary to store metrics for each run of the current expert\n",
    "        run_metrics = {}\n",
    "\n",
    "        for run_idx, run_data in enumerate(expert_runs):\n",
    "            actual = []\n",
    "            prediction = []\n",
    "            unknown_classes = []\n",
    "\n",
    "            for img, data in run_data.items():\n",
    "                actual_class = data[\"expectation\"].lower()\n",
    "                pred_class = extract_output(data[\"prediction\"])\n",
    "\n",
    "                if pred_class not in class_mapping:\n",
    "                    unknown_classes.append((img, actual_class, pred_class))\n",
    "                    continue\n",
    "                else:\n",
    "                    pred_label = class_mapping[pred_class]\n",
    "                    prediction.append(pred_label)\n",
    "                    actual_label = class_mapping[actual_class]\n",
    "                    actual.append(actual_label)\n",
    "\n",
    "            # Compute metrics\n",
    "            accuracy = accuracy_score(actual, prediction) * 100\n",
    "            precision = precision_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"], zero_division=0) * 100\n",
    "            recall = recall_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"], zero_division=0) * 100\n",
    "            f1 = f1_score(actual, prediction, average='binary', pos_label=class_mapping[\"abnormal\"], zero_division=0) * 100\n",
    "            specificity = recall_score(actual, prediction, average='binary', pos_label=class_mapping[\"normal\"], zero_division=0) * 100\n",
    "\n",
    "            # Store metrics for the current run\n",
    "            # run_metrics[f\"accuracy_run{run_idx + 1}\"] = accuracy\n",
    "            # run_metrics[f\"precision_run{run_idx + 1}\"] = precision\n",
    "            # run_metrics[f\"recall_run{run_idx + 1}\"] = recall\n",
    "            # run_metrics[f\"f1_run{run_idx + 1}\"] = f1\n",
    "            # run_metrics[f\"specificity_run{run_idx + 1}\"] = specificity\n",
    "\n",
    "            run_metrics[f\"accuracy_run{run_idx + 1}\"] = round(accuracy, 4)\n",
    "            run_metrics[f\"precision_run{run_idx + 1}\"] = round(precision, 4)\n",
    "            run_metrics[f\"recall_run{run_idx + 1}\"] = round(recall, 4)\n",
    "            run_metrics[f\"f1_run{run_idx + 1}\"] = round(f1, 4)\n",
    "            run_metrics[f\"specificity_run{run_idx + 1}\"] = round(specificity, 4)\n",
    "\n",
    "        # Store metrics for the current expert\n",
    "        expert_metrics[expert_name] = run_metrics\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    metrics_df = pd.DataFrame.from_dict(expert_metrics, orient='index')\n",
    "    column_order = ['accuracy_run1', 'accuracy_run2', 'accuracy_run3', 'accuracy_run4', 'accuracy_run5',\n",
    "                'precision_run1', 'precision_run2', 'precision_run3', 'precision_run4', 'precision_run5',\n",
    "                'recall_run1', 'recall_run2', 'recall_run3', 'recall_run4', 'recall_run5',\n",
    "                'specificity_run1', 'specificity_run2', 'specificity_run3', 'specificity_run4', 'specificity_run5',\n",
    "                'f1_run1', 'f1_run2', 'f1_run3', 'f1_run4', 'f1_run5']\n",
    "    metrics_df = metrics_df.loc[:, column_order]\n",
    "    return metrics_df\n",
    "\n",
    "# Create the DataFrame\n",
    "metrics_df = create_metrics_dataframe(all_expert_5_runs_results, class_mapping)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1516,
     "status": "ok",
     "timestamp": 1739419816411,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "4HfCQR_lf3Vt"
   },
   "outputs": [],
   "source": [
    "metrics_df.to_excel(\"all_runs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1737086440629,
     "user": {
      "displayName": "Anwesh Nayak",
      "userId": "10812060260948452341"
     },
     "user_tz": -330
    },
    "id": "s5OFz1C8ZzyS",
    "outputId": "4476bb34-e8a4-4e64-c71d-0aa6cde27652"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "\n",
    "# Define class mappings\n",
    "class_mapping = {\"normal\": 1,\"lesion\": 0}\n",
    "\n",
    "# Prepare an Excel writer\n",
    "output_file = \"/content/drive/MyDrive/Binary_classification_using_LLMs/Few Shot Learning/Results/classification_results_with_paths.xlsx\"\n",
    "writer = pd.ExcelWriter(output_file, engine=\"xlsxwriter\")\n",
    "\n",
    "# Process results for each run\n",
    "for run_name, run_data in results.items():\n",
    "    print(f\"Processing {run_name}...\")\n",
    "\n",
    "    # Initialize lists for actual, prediction, and misclassification\n",
    "    actual = []\n",
    "    prediction = []\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    unknown_classes = []\n",
    "\n",
    "    # Process each image\n",
    "    for img_path, data in tqdm(run_data.items(), desc=f\"Processing images for {run_name}\"):\n",
    "        actual_class = data[\"expectation\"]\n",
    "        pred_class = data[\"prediction\"]\n",
    "        query_image_path = data[\"query_image_path\"]\n",
    "\n",
    "        if pred_class not in class_mapping or actual_class not in class_mapping:\n",
    "            unknown_classes.append((query_image_path, actual_class, pred_class))\n",
    "            continue\n",
    "\n",
    "        actual_label = class_mapping[actual_class]\n",
    "        pred_label = class_mapping[pred_class]\n",
    "        actual.append(actual_label)\n",
    "        prediction.append(pred_label)\n",
    "\n",
    "        # Classify misclassifications\n",
    "        if actual_label != pred_label:\n",
    "            if pred_label == class_mapping[\"lesion\"]:\n",
    "                false_positives.append(query_image_path)  # Predicted lesion, but actual is normal\n",
    "            else:\n",
    "                false_negatives.append(query_image_path)  # Predicted normal, but actual is lesion\n",
    "\n",
    "    # Save false positives and false negatives to a DataFrame\n",
    "    misclass_df = pd.DataFrame({\n",
    "        \"False Positives (Image Path)\": false_positives + [\"\"] * (len(false_negatives) - len(false_positives)),\n",
    "        \"False Negatives (Image Path)\": false_negatives + [\"\"] * (len(false_positives) - len(false_negatives))\n",
    "    })\n",
    "    misclass_df.to_excel(writer, sheet_name=f\"{run_name}_Misclassifications\", index=False)\n",
    "\n",
    "    # Save unknown classes to a DataFrame\n",
    "    unknown_df = pd.DataFrame(unknown_classes, columns=[\"Image Path\", \"Expectation\", \"Prediction\"])\n",
    "    if not unknown_df.empty:\n",
    "        unknown_df.to_excel(writer, sheet_name=f\"{run_name}_Unknown\", index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.close()\n",
    "print(f\"Results saved to {output_file}.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO0PTcknt6W9yK+HDTsLZii",
   "mount_file_id": "1PuvYbPPrIUkw-R3ii_34NQN7LJIRSnXb",
   "provenance": [
    {
     "file_id": "1pLz35qvgWpST1l-0aGN4bbOcOizhdBVq",
     "timestamp": 1736874963867
    },
    {
     "file_id": "1Zx0jp0Ou_5sude3mKLOXS-3kRlorEPQ8",
     "timestamp": 1732952694297
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
